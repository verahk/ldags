---
title: 'Use BiDAG-package with user-defined score'
author: "Vera Kvisgaard"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	results = "hold"
)
```

This note shows how the `BiDAG` package can be manipulated used to learn labeled DAGs. 
```{r prep, message=FALSE}
library(pcalg)
library(BiDAG)

# prep
here::i_am("./rmd/BiDAG_with_user_defined_score.Rmd")
files <- list.files(here::here("R"), ".R", full.names = T)
sapply(files, source)
```

## Define netowrk with context-specific independencies
Define a Bayesian network over three nodes, a collider structure, where the CPT of the collider node $Y$ contains context-specific independence, labels on the edges pointing into $Y$. 
```{r}
dag <- rbind(Z = c(0, 0, 1),
             X = c(0, 0, 1),
             Y = c(0, 0, 0))
colnames(dag) <- rownames(dag)
Rgraphviz::plot(as(dag, "graphNEL"))
```

The distribution is designed to illustrate when labeled DAGs can help directing edges.
With dependendence only in one single context, the direction is the of edges is hard to detect.
```{r}

cpts <- setNames(vector("list", ncol(dag)), colnames(dag))
levels <- rep(list(0:1), 3)
names(levels) <- names(cpts)
nlev <- lengths(levels)
n <- length(nlev)


cpts$Z <- array(c(.5, .5), 2, levels["Z"])
cpts$X <- array(c(.5, .5), 2, levels[c("X")])

# encode some "weak" context-specific independence
# Y is independent of Z given X = 0 and independent on X given Z = 0
p <- .75
cpts$Y <- array(c(rep(c(p, 1-p), 3), 1-p, p), 
                c(2, 2, 2), 
                levels[c("Y", "Z", "X")])
cpts
```


Store as `bn.fit` object and sample data:
```{r}

g <- bnlearn::empty.graph(names(cpts))
bnlearn::amat(g) <- dag
bn <- bnlearn::custom.fit(g, cpts)

set.seed(007)
df <- bnlearn::rbn(bn, 100)
data <- sapply(df, as.numeric) -1

```


## Optimize local CSI structure:
The function `optimize_CSI_structure` runs a greedy search for the optimal CSI-consistent partition for binary variables. 
```{r}
cat("\nOptimized CSI-structure:\n")
optimize_CSI_structure(data, nlev, 3, 1:2, ess = 1, kappa = .5)
sum(optimize_CSI_structure(data, nlev, 3, 1:2, ess = 1, kappa = .5)$scores)

cat("\nFull CPT:\n")
optimize_CSI_structure(data, nlev, 3, 1:2, ess = 1, kappa = 0)
sum(optimize_CSI_structure(data, nlev, 3, 1:2, ess = 1, kappa = 0)$scores)
```


Compare the local CSI-score of node `Y` with different parent sets:
```{r}
cat("Local scores:\n")
local_CSI_score(data, nlev, 3, integer(0), ess = 1, kappa = .5)$score
local_CSI_score(data, nlev, 3, 1, ess = 1, kappa = .5)$score
local_CSI_score(data, nlev, 3, 2, ess = 1, kappa = .5)$score
local_CSI_score(data, nlev, 3, 1:2, ess = 1, kappa = .5)$score
```

Check observed sample proportions
```{r}
cat("\n observed P(Y|X, Z):\n")
counts <- table(df[, c("Y", "Z", "X")])
counts/rep(colSums(counts), each = 2)

```

## Run `BiDAG::iterativeMCMC` with user-specified function

Define a `scoreparameters`-object for `BiDAG`'s MCMC functions. 
Note that the level of each variable is added to the list of parameters. 
I think this argument is used in the PC-algorithm-step, but it is not added when `type = "usr"`.
```{r}
library(BiDAG)
scorepar <- scoreparameters("usr", 
                         data = data,
                         usrpar = list(pctesttype = "bdecat"))
scorepar$Cvec <- nlev

```


Define the user-specified scoring function that is to be called from `BiDAG`-functions.
Store lookuptable in a `rlang::env` environment, to modify the table without copying it.
```{r, file = here::here("./R/score_from_lookup.R")}

```

Define a wrapper function with same arguments as the `BIDAG:::usrDAGcorescore` function and
assign this function to the name-space of `BiDAG`-package, as otherwise the internal function is called. 
```{r,}

# wrapper function
usrDAGcorescore <- function(j, parentnodes, n, scorepar) {
  score_from_lookup(scorepar$data, scorepar$Cvec, j, parentnodes, scorepar$tab)
}

# assign to namespace
assignInNamespace("usrDAGcorescore", usrDAGcorescore, ns = "BiDAG")

# init score table
scorepar$tab <- init_lookup_scoretable(ncol(data), list(ess = 1, kappa = .5))
usrDAGcorescore(1, 2:3, ncol(data), scorepar)
ls.str(scorepar$tab)


```



Run iterativeMCMC: 
```{r}
iterativefit <- learnBN(scorepar, algorithm = "orderIter", scoreout = T, verbose = T)
plot(unlist(iterativefit$trace), type = "l")
summary(iterativefit)
```


Plot MAP DAG and score, and check that the score equals the sum of all local CSIs-scores.
```{r}
iterativefit$DAG
iterativefit$score

tmp <- sapply(seq_along(bn), 
              function(j) usrDAGcorescore(j, which(iterativefit$DAG[, j] == 1), n = length(bn), scorepar))
all(sum(tmp) == iterativefit$score)
```

Plot list with CSI-tables and scores:
```{r}
str(tab$scores, max.level = 2)
```


# Repeat using standard BDeu-score
```{r}
scorepar <- scoreparameters("bdecat", 
                         data = df,
                         bdecatpar = list(chi = 1, edgepf = 1))
iterativefit <- learnBN(scorepar, algorithm = "orderIter", scoreout = T, verbose = T)

iterativefit$DAG
iterativefit$score
```

```{r}
BiDAG:::DAGcorescore(3, integer(0), 3, scorepar)
BiDAG:::DAGcorescore(3, 1, 3, scorepar)
BiDAG:::DAGcorescore(3, 2, 3, scorepar)
BiDAG:::DAGcorescore(3, 1:2, 3, scorepar)
```

